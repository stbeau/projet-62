{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Pipeline: Wrapping up for Deployment\n",
    "\n",
    "\n",
    "Here, we will summarise, the key pieces of code, that we need to take forward, for this particular project, to put our model in production.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josal\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# to persist the model and the scaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed\n",
    "\n",
    "\n",
    "Important note **Always set the seeds**.\n",
    "\n",
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 13,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We need the training data to train our model in the production environment. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329275, 14)\n"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(629364, 10)\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>code_postal</th>\n",
       "      <th>date_mutation</th>\n",
       "      <th>id_parcelle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nature_culture</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>nombre_lots</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
       "      <th>numero_disposition</th>\n",
=======
       "      <th>code_commune</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nature_culture</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>type_local</th>\n",
       "      <th>valeur_fonciere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>9800.0</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>092630000A0991</td>\n",
       "      <td>42.936027</td>\n",
       "      <td>0.931099</td>\n",
       "      <td>jardins</td>\n",
       "      <td>Saint-Jean-du-Castillonnais</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78450.0</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>78674000ZL0016</td>\n",
       "      <td>48.840698</td>\n",
       "      <td>2.000984</td>\n",
       "      <td>prés</td>\n",
       "      <td>Villepreux</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>78440.0</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>783170000B0236</td>\n",
       "      <td>49.051101</td>\n",
       "      <td>1.843135</td>\n",
       "      <td>taillis sous futaie</td>\n",
       "      <td>Jambville</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44550.0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>44103000AB0121</td>\n",
       "      <td>47.327899</td>\n",
       "      <td>-2.153218</td>\n",
       "      <td>sols</td>\n",
       "      <td>Montoir-de-Bretagne</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Local industriel. commercial ou assimilé</td>\n",
       "      <td>243420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>11069000AE0372</td>\n",
       "      <td>43.218986</td>\n",
       "      <td>2.346464</td>\n",
       "      <td>sols</td>\n",
       "      <td>Carcassonne</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>131500.0</td>\n",
=======
       "      <td>1053</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>46.198840</td>\n",
       "      <td>5.209562</td>\n",
       "      <td>aucune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>37220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1314</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>45.999566</td>\n",
       "      <td>5.282104</td>\n",
       "      <td>sols</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>209000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1350</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>46.293278</td>\n",
       "      <td>5.299929</td>\n",
       "      <td>sols</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>134900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>46.269978</td>\n",
       "      <td>5.174803</td>\n",
       "      <td>sols</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>192000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1106</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>46.205294</td>\n",
       "      <td>5.452079</td>\n",
       "      <td>sols</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>45000.0</td>\n",
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   code_postal date_mutation     id_parcelle   latitude  longitude  \\\n",
       "0       9800.0    2019-09-06  092630000A0991  42.936027   0.931099   \n",
       "1      78450.0    2019-12-13  78674000ZL0016  48.840698   2.000984   \n",
       "2      78440.0    2019-03-05  783170000B0236  49.051101   1.843135   \n",
       "3      44550.0    2019-10-30  44103000AB0121  47.327899  -2.153218   \n",
       "4      11000.0    2019-04-20  11069000AE0372  43.218986   2.346464   \n",
       "\n",
       "        nature_culture                  nom_commune  nombre_lots  \\\n",
       "0              jardins  Saint-Jean-du-Castillonnais            0   \n",
       "1                 prés                   Villepreux            0   \n",
       "2  taillis sous futaie                    Jambville            0   \n",
       "3                 sols          Montoir-de-Bretagne            0   \n",
       "4                 sols                  Carcassonne            0   \n",
       "\n",
       "   nombre_pieces_principales  numero_disposition  surface_reelle_bati  \\\n",
       "0                        NaN                   1                  NaN   \n",
       "1                        NaN                   1                  NaN   \n",
       "2                        NaN                   1                  NaN   \n",
       "3                        0.0                   1                 60.0   \n",
       "4                        5.0                   1                106.0   \n",
       "\n",
       "   surface_terrain                                type_local  valeur_fonciere  \n",
       "0            245.0                                       NaN         167220.0  \n",
       "1           4050.0                                       NaN        1007200.0  \n",
       "2          56465.0                                       NaN         320000.0  \n",
       "3             98.0  Local industriel. commercial ou assimilé         243420.0  \n",
       "4           1223.0                                    Maison         131500.0  "
      ]
     },
     "execution_count": 4,
=======
       "  code_commune  code_postal   latitude  longitude nature_culture  \\\n",
       "0         1053       1000.0  46.198840   5.209562         aucune   \n",
       "1         1314       1160.0  45.999566   5.282104           sols   \n",
       "2         1350       1370.0  46.293278   5.299929           sols   \n",
       "3         1024       1340.0  46.269978   5.174803           sols   \n",
       "4         1106       1250.0  46.205294   5.452079           sols   \n",
       "\n",
       "   nombre_pieces_principales  surface_reelle_bati  surface_terrain  \\\n",
       "0                        1.0                 20.0              0.0   \n",
       "1                        4.0                 90.0            940.0   \n",
       "2                        5.0                101.0            490.0   \n",
       "3                        4.0                 88.0            708.0   \n",
       "4                        2.0                 39.0            631.0   \n",
       "\n",
       "    type_local  valeur_fonciere  \n",
       "0  Appartement          37220.0  \n",
       "1       Maison         209000.0  \n",
       "2       Maison         134900.0  \n",
       "3       Maison         192000.0  \n",
       "4       Maison          45000.0  "
      ]
     },
     "execution_count": 5,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
<<<<<<< HEAD
    "data = pd.read_csv('../../data/interim/raw_useful_ftrs.csv')\n",
=======
    "data_in = pd.read_csv('../../data/interim/raw_useful_ftrs.csv')\n",
    "data = data_in.dropna()\n",
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 161,
=======
   "execution_count": 14,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
      "RangeIndex: 329275 entries, 0 to 329274\n",
      "Data columns (total 14 columns):\n",
      "code_postal                  329143 non-null float64\n",
      "date_mutation                329275 non-null object\n",
      "id_parcelle                  329275 non-null object\n",
      "latitude                     322415 non-null float64\n",
      "longitude                    322415 non-null float64\n",
      "nature_culture               243611 non-null object\n",
      "nom_commune                  329275 non-null object\n",
      "nombre_lots                  329275 non-null int64\n",
      "nombre_pieces_principales    180225 non-null float64\n",
      "numero_disposition           329275 non-null int64\n",
      "surface_reelle_bati          141350 non-null float64\n",
      "surface_terrain              243602 non-null float64\n",
      "type_local                   180434 non-null object\n",
      "valeur_fonciere              329275 non-null float64\n",
      "dtypes: float64(7), int64(2), object(5)\n",
      "memory usage: 35.2+ MB\n"
=======
      "Int64Index: 629364 entries, 0 to 629388\n",
      "Data columns (total 10 columns):\n",
      "code_commune                 629364 non-null object\n",
      "code_postal                  629364 non-null object\n",
      "latitude                     629364 non-null float64\n",
      "longitude                    629364 non-null float64\n",
      "nature_culture               629364 non-null object\n",
      "nombre_pieces_principales    629364 non-null float64\n",
      "surface_reelle_bati          629364 non-null float64\n",
      "surface_terrain              629364 non-null float64\n",
      "type_local                   629364 non-null object\n",
      "valeur_fonciere              629364 non-null float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 52.8+ MB\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode code postal as object (This should be done on EDA Preproc Script)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 15,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
      "RangeIndex: 329275 entries, 0 to 329274\n",
      "Data columns (total 14 columns):\n",
      "code_postal                  329143 non-null object\n",
      "date_mutation                329275 non-null object\n",
      "id_parcelle                  329275 non-null object\n",
      "latitude                     322415 non-null float64\n",
      "longitude                    322415 non-null float64\n",
      "nature_culture               243611 non-null object\n",
      "nom_commune                  329275 non-null object\n",
      "nombre_lots                  329275 non-null int64\n",
      "nombre_pieces_principales    180225 non-null float64\n",
      "numero_disposition           329275 non-null int64\n",
      "surface_reelle_bati          141350 non-null float64\n",
      "surface_terrain              243602 non-null float64\n",
      "type_local                   180434 non-null object\n",
      "valeur_fonciere              329275 non-null float64\n",
      "dtypes: float64(6), int64(2), object(6)\n",
      "memory usage: 35.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(329275, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,'code_postal'] = data.loc[:,'code_postal'].astype('object')\n",
    "data.info()\n",
    "data.shape"
=======
      "Int64Index: 629364 entries, 0 to 629388\n",
      "Data columns (total 10 columns):\n",
      "code_commune                 629364 non-null object\n",
      "code_postal                  629364 non-null object\n",
      "latitude                     629364 non-null float64\n",
      "longitude                    629364 non-null float64\n",
      "nature_culture               629364 non-null object\n",
      "nombre_pieces_principales    629364 non-null float64\n",
      "surface_reelle_bati          629364 non-null float64\n",
      "surface_terrain              629364 non-null float64\n",
      "type_local                   629364 non-null object\n",
      "valeur_fonciere              629364 non-null float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 52.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.loc[:,'code_postal'] = data.loc[:,'code_postal'].astype('str')\n",
    "data.info()"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 16,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "adresse_code_voie               False\n",
       "adresse_nom_voie                False\n",
       "adresse_numero                  False\n",
       "adresse_suffixe                 False\n",
       "ancien_code_commune             False\n",
       "ancien_id_parcelle              False\n",
       "ancien_nom_commune              False\n",
       "code_commune                    False\n",
       "code_departement                False\n",
       "code_nature_culture             False\n",
       "code_nature_culture_speciale    False\n",
       "code_postal                      True\n",
       "code_type_local                 False\n",
       "date_mutation                    True\n",
       "id_mutation                     False\n",
       "id_parcelle                      True\n",
       "latitude                         True\n",
       "longitude                        True\n",
       "lot1_numero                     False\n",
       "lot1_surface_carrez             False\n",
       "lot2_numero                     False\n",
       "lot2_surface_carrez             False\n",
       "lot3_numero                     False\n",
       "lot3_surface_carrez             False\n",
       "lot4_numero                     False\n",
       "lot4_surface_carrez             False\n",
       "lot5_numero                     False\n",
       "lot5_surface_carrez             False\n",
       "nature_culture                   True\n",
       "nature_culture_speciale         False\n",
       "nature_mutation                 False\n",
       "nom_commune                      True\n",
       "nombre_lots                      True\n",
       "nombre_pieces_principales        True\n",
       "numero_disposition               True\n",
       "numero_volume                   False\n",
       "surface_reelle_bati              True\n",
       "surface_terrain                  True\n",
       "type_local                       True\n",
       "valeur_fonciere                 False\n",
       "Name: use_ftr, dtype: bool"
      ]
     },
     "execution_count": 8,
=======
       "['code_commune',\n",
       " 'code_postal',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'nature_culture',\n",
       " 'nombre_pieces_principales',\n",
       " 'surface_reelle_bati',\n",
       " 'surface_terrain',\n",
       " 'type_local',\n",
       " 'valeur_fonciere']"
      ]
     },
     "execution_count": 16,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset tags on features to use\n",
    "features_csv= pd.read_csv('../../data/interim/features_to_use_summary.csv', index_col=0)\n",
    "print(features_csv.shape)\n",
<<<<<<< HEAD
    "features_csv.use_ftr.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate dataset into train and test\n",
    "\n",
    "Before beginning to engineer our features, it is important to separate our data intro training and testing set. This is to avoid over-fitting. There is an element of randomness in dividing the dataset, so remember to set the seed."
=======
    "\n",
    "features_csv[['use_ftr']].sort_values(by=['use_ftr'], ascending=False).head(10)\n",
    "ftrs = list(features_csv.loc[features_csv.use_ftr==True,'use_ftr'].index)\n",
    "ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 629364 entries, 0 to 629388\n",
      "Data columns (total 7 columns):\n",
      "latitude                     629364 non-null float64\n",
      "longitude                    629364 non-null float64\n",
      "nombre_pieces_principales    629364 non-null float64\n",
      "surface_reelle_bati          629364 non-null float64\n",
      "surface_terrain              629364 non-null float64\n",
      "type_local                   629364 non-null object\n",
      "valeur_fonciere              629364 non-null float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 38.4+ MB\n"
     ]
    }
   ],
   "source": [
    "leave_out_ftrs = ['nature_culture', 'code_postal', 'code_commune']\n",
    "data2 = data.loc[:,[c for c in ftrs if c not in leave_out_ftrs]]\n",
    "data2.info() \n",
    "\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 164,
=======
   "execution_count": 18,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": [
       "((296347, 14), (32928, 14))"
      ]
     },
     "execution_count": 164,
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2107700</td>\n",
       "      <td>48.86</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>826300</td>\n",
       "      <td>43.31</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>443600</td>\n",
       "      <td>45.76</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>417400</td>\n",
       "      <td>43.62</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice</td>\n",
       "      <td>329800</td>\n",
       "      <td>43.70</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank       city  population  latitude  longitude\n",
       "0     1      Paris     2107700     48.86       2.34\n",
       "1     2  Marseille      826300     43.31       5.37\n",
       "2     3       Lyon      443600     45.76       4.83\n",
       "3     4   Toulouse      417400     43.62       1.45\n",
       "4     5       Nice      329800     43.70       7.27"
      ]
     },
     "execution_count": 18,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Let's separate into train and test set\n",
    "# Remember to seet the seed (random_state for this sklearn function)\n",
    "# \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.valeur_fonciere,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=SEED) # we are setting the seed here\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected features\n",
    "\n",
    "Remember that we will deploy our model utilising only a subset of features, the most predictive ones. This is to make simpler models, so that we build simpler code for deployment. We will tell you more about this in coming lectures."
=======
    "# load External data \n",
    "big_cities = pd.read_csv('../../data/external/france_big_cities.csv', sep = ';')\n",
    "big_cities.head()"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  13\n"
     ]
    }
   ],
   "source": [
    "# load selected features\n",
    "features = list(features_csv.loc[features_csv.use_ftr==True, :].index)\n",
    "...\n",
    "features\n",
    "\n",
    "print('Number of features: ', len(features))\n",
    "# Remember that add extra ftrs additional feature engineering step into production as p.ex distance_to_big_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "For categorical variables, we will fill missing information by adding an additional category: \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a list of the categorical variables that contain missing values\n",
    "vars_with_na = [var for var in features if X_train[var].isnull().sum()>1 and X_train[var].dtypes=='O']\n",
    "\n",
    "# print the variable name and the percentage of missing values\n",
    "# for var in vars_with_na:\n",
    "#     print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still categorical variables with NA for the final model, so we need to include this piece of feature engineering logic in the deployment pipeline to input those NA values."
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>type_local</th>\n",
       "      <th>valeur_fonciere</th>\n",
       "      <th>close_big_city_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>629384</td>\n",
       "      <td>48.865949</td>\n",
       "      <td>2.350482</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>1.012676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629385</td>\n",
       "      <td>48.854584</td>\n",
       "      <td>2.362102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>696500.0</td>\n",
       "      <td>1.725474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629386</td>\n",
       "      <td>48.854241</td>\n",
       "      <td>2.358859</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>852400.0</td>\n",
       "      <td>1.521081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629387</td>\n",
       "      <td>48.867594</td>\n",
       "      <td>2.337572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>680000.0</td>\n",
       "      <td>0.862890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629388</td>\n",
       "      <td>48.866431</td>\n",
       "      <td>2.348095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>0.928443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude  nombre_pieces_principales  surface_reelle_bati  \\\n",
       "629384  48.865949   2.350482                        2.0                 42.0   \n",
       "629385  48.854584   2.362102                        2.0                 50.0   \n",
       "629386  48.854241   2.358859                        2.0                 67.0   \n",
       "629387  48.867594   2.337572                        3.0                 72.0   \n",
       "629388  48.866431   2.348095                        3.0                 97.0   \n",
       "\n",
       "        surface_terrain   type_local  valeur_fonciere  close_big_city_dist  \n",
       "629384              0.0  Appartement         480000.0             1.012676  \n",
       "629385              0.0  Appartement         696500.0             1.725474  \n",
       "629386              0.0  Appartement         852400.0             1.521081  \n",
       "629387              0.0  Appartement         680000.0             0.862890  \n",
       "629388              0.0  Appartement        1400000.0             0.928443  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add columns with radians for latitude and longitude\n",
    "import sklearn\n",
    "\n",
    "cities_radians = data2.loc[:,['latitude', 'longitude']].apply(np.radians)\n",
    "big_cities_radians = big_cities.apply({'latitude':np.radians, 'longitude':np.radians})\n",
    "big_cities_radians.tail()\n",
    "\n",
    "\n",
    "dist = sklearn.neighbors.DistanceMetric.get_metric('haversine')\n",
    "\n",
    "\n",
    "# for i,r in data2.head(2).iterrows():\n",
    "#     ith = pd.DataFrame((cities_radians.loc[i, ['latitude','longitude']].values.reshape(1,-1))\n",
    "#                        , index = [0], columns =['latitude','longitude'])\n",
    "\n",
    "#     distances = np.ravel(dist.pairwise(ith, big_cities[['latitude','longitude']]))* 6371\n",
    "\n",
    "#     closest_dist = distances[np.argmin(distances)]\n",
    "#     farest_dist =  distances[np.argmax(distances)]\n",
    "    \n",
    "#     closest_name = big_cities.city[np.argsort(distances)[0]]\n",
    "#     farest_name = big_cities.city[np.argsort(distances)[::-1][0]]\n",
    "#     print(distances)\n",
    "#     print(closest_name, closest_dist, farest_name, farest_dist )\n",
    "#     #data2['close_big_city_dist'] = clostes\n",
    "    \n",
    "dist_matrix = pd.DataFrame(dist.pairwise\n",
    "    (cities_radians[['latitude','longitude']],\n",
    "     big_cities_radians[['latitude','longitude']])*6371 # 6371 kms is average radius of the earth\n",
    "    ,index=cities_radians.index, columns = big_cities.city\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data2['close_big_city_dist'] = dist_matrix.apply(np.min, axis = 1)\n",
    "data2.tail()"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 167,
=======
   "execution_count": 322,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": [
       "code_postal       0\n",
       "nature_culture    0\n",
       "type_local        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next functio can go  in the feature engineering notebook:\n",
    "\n",
    "# function to replace NA in categorical variables\n",
    "def fill_categorical_na(df, var_list):\n",
    "    X = df.copy()\n",
    "    X[var_list] = df[var_list].fillna('Missing')\n",
    "    return X\n",
    "\n",
    "# replace missing values with new label: \"Missing\"\n",
    "X_train = fill_categorical_na(X_train, vars_with_na)\n",
    "X_test = fill_categorical_na(X_test, vars_with_na)\n",
    "\n",
    "# check that we have no missing information in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
=======
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "data2.close_big_city_dist.plot.hist(ax = ax, bins = 70)\n",
    "plt.xlim(0,125)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and set up default values\n",
    "from sklearn import (model_selection, preprocessing, linear_model, naive_bayes\n",
    "                     , metrics)\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "\n",
    "#import xgboost # A lot more optimized than sci-kit learn one\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "import io\n",
    "#import aux_functions_mod  #Custom own functions"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "For numerical variables, we are going to add an additional variable capturing the missing information, and then replace the missing information in the original variable by the mode, or most frequent value:"
=======
    "#### Num Ftrs"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude 0.021  % missing values\n",
      "longitude 0.021  % missing values\n",
      "nombre_pieces_principales 0.452  % missing values\n",
      "surface_reelle_bati 0.571  % missing values\n",
      "surface_terrain 0.261  % missing values\n"
     ]
    }
   ],
   "source": [
    "# make a list of the numerical variables that contain missing values\n",
    "vars_with_na = [var for var in features if X_train[var].isnull().sum()>1 and X_train[var].dtypes!='O']\n",
    "vars_with_na\n",
    "# print the variable name and the percentage of missing values\n",
    "for var in vars_with_na:\n",
    "    print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')"
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'nombre_pieces_principales',\n",
       " 'surface_reelle_bati',\n",
       " 'surface_terrain']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Ftr Types\n",
    "num_ftrs = list(data2.select_dtypes('number').columns)\n",
    "num_ftrs.remove('valeur_fonciere')\n",
    "num_ftrs \n",
    "\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "It seems however that surfacer_reelle_bati and surface_trrain should be inputed to zero while others can be inputed to median"
=======
    "#### Cat Ftrs"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_na_at_zero = ['surface_reelle_bati', 'surface_terrain']"
=======
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's capture the categorical variables first\n",
    "cat_ftrs = [var for var in data2.columns if data2[var].dtype == 'O']\n",
    "cat_ftrs\n",
    "\n",
    "# Label encoder needs cat ftrs to be string.\n",
    "for f in cat_ftrs:\n",
    "    data2[f] = data2[f].astype(str)"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Important: persisting the mean value for NA imputation\n",
    "\n",
    "As you will see in future sections, one of the key pieces of deploying the model is \"Model Validation\". Model validation refers to corroborating that the deployed model and the model built during research, are identical. The entire pipeline needs to produce identical results.\n",
    "\n",
    "Therefore, in order to check at the end of the process that the feature engineering pipelines are identical, we will save -we will persist-, the mean value of the variable, so that we can use it at the end, to corroborate our models."
=======
    "### Separate dataset into train and test\n",
    "\n",
    "Before beginning to engineer our features, it is important to separate our data intro training and testing set. This is to avoid over-fitting. There is an element of randomness in dividing the dataset, so remember to set the seed."
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 170,
=======
   "execution_count": 22,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "latitude                     0\n",
       "longitude                    0\n",
       "nombre_pieces_principales    0\n",
       "surface_reelle_bati          0\n",
       "surface_terrain              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
=======
       "Index(['latitude', 'longitude', 'nombre_pieces_principales',\n",
       "       'surface_reelle_bati', 'surface_terrain', 'type_local',\n",
       "       'valeur_fonciere'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# replace the missing values\n",
    "\n",
    "mean_var_dict = {}\n",
    "\n",
    "for var in vars_with_na:\n",
    "    \n",
    "    # calculate the mode\n",
    "    mode_val = X_train[var].mode()[0]\n",
    "    \n",
    "    # we persist the mean in the dictionary\n",
    "    mean_var_dict[var] = mode_val\n",
    "    \n",
    "    # train\n",
    "    # note  that the additional binary variable was not selected, so we don't need this step any more\n",
    "    #X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_train[var].fillna(mode_val, inplace=True)\n",
    "    \n",
    "    # test\n",
    "    # note  that the additional binary variable was not selected, so we don't need this step any more\n",
    "    #X_test[var+'_na'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "    X_test[var].fillna(mode_val, inplace=True)\n",
    "\n",
    "# we save the dictionary for later\n",
    "np.save('../../models/mean_var_dict.npy', mean_var_dict)\n",
    "\n",
    "# check that we have no more missing values in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal variables\n",
    "\n",
    "We can add here some temporal EDA features, such as date transformations."
=======
    "data2.loc[:,data2.columns[:-2]].columns\n",
    "data2.columns"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the temporal var \"elapsed years\"\n",
    "# def elapsed_years(df, var):\n",
    "#     # capture difference between year variable and year the house was sold\n",
    "#     df[var] = df['YrSold'] - df[var]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = elapsed_years(X_train, 'YearRemodAdd')\n",
    "# X_test = elapsed_years(X_test, 'YearRemodAdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables\n",
    "\n",
    "We will log transform some numerical variables that do not contain zeros in order to get a more Gaussian-like distribution. This tends to help Linear machine learning models.\n"
=======
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 566427 entries, 510716 to 277885\n",
      "Data columns (total 6 columns):\n",
      "latitude                     566427 non-null float64\n",
      "longitude                    566427 non-null float64\n",
      "nombre_pieces_principales    566427 non-null float64\n",
      "surface_reelle_bati          566427 non-null float64\n",
      "surface_terrain              566427 non-null float64\n",
      "type_local                   566427 non-null object\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 30.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to seet the seed (random_state for this sklearn function)\n",
    "# \n",
    "X_train, X_test, y_train, y_test = train_test_split(data2.loc[:,data2.columns[:-1]], data2.valeur_fonciere,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=SEED) # we are setting the seed here\n",
    "X_train.shape, X_test.shape\n",
    "X_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'nombre_lots', 'nombre_pieces_principales',\n",
       "       'numero_disposition', 'surface_reelle_bati', 'surface_terrain',\n",
       "       'valeur_fonciere'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_ftrs = X_train.select_dtypes('number').columns\n",
    "num_ftrs"
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (from lightgbm) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\josal\\mlprojs\\bdbai\\proysyntbdb2\\projet-62\\notebooks\\modeling\\venv\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs_to_log_transf = ['valeur_fonciere']\n",
    "for var in ftrs_to_log_transf:\n",
    "    X_train[var] = np.log1p(X_train[var])\n",
    "    X_test[var]= np.log1p(X_test[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "We do have categorical variables in our final model. First, we will remove those categories within variables that are present in less than 1% of the observations:"
=======
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grid search space size: 1 combinations to test\n",
      "dict_keys(['lasso', 'lgbmr'])\n",
      "Training model lasso ...\n",
      "{'lasso__alpha': [1]}\n",
      "Best mean_squared_error: 0.7499 with params: {'lasso__alpha': 1}: \n",
      "Training model lgbmr ...\n",
      "{'lgbmr__n_estimators': [100]}\n",
      "Best mean_squared_error: 0.4406 with params: {'lgbmr__n_estimators': 100}: \n",
      "Grid search elapsed time: 0.98 minutes\n"
     ]
    }
   ],
   "source": [
    "# =======================Training Pipeline=================================\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import model_selection\n",
    "from tempfile import mkdtemp\n",
    "from joblib import Memory\n",
    "from sklearn.feature_selection import chi2, SelectPercentile #SelectFromModel\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "\n",
    "FIX_RAND_STATE = SEED\n",
    "\n",
    "# Set temp storage to cache first pipe transformations\n",
    "#cachedir = mkdtemp()\n",
    "#memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "cached_pipe = Pipeline(steps=[('preprocessor', preprocessor)\n",
    "                      ,#('classifier', LogisticRegression())\n",
    "                             ])\n",
    "\n",
    "\n",
    "\n",
    "## Delete the temporary cache\n",
    "#before exiting\n",
    "#from shutil import rmtree\n",
    "#rmtree(cachedir)\n",
    "\n",
    "\n",
    "params_grid = {\n",
    "\n",
    "               #, 'ftr_select_percent__percentile': [5,10,20,50] #, 10, 20, 40Retain nth perc\n",
    "               #, 'feature_select__threshold': [.05, .1] # Drops features with weights under threshold\n",
    "             }\n",
    "\n",
    "\n",
    "# Set models and hyperparameters\n",
    "models = [\n",
    "          #  ('nb', naive_bayes.MultinomialNB())\n",
    "           ('lasso', linear_model.Ridge( random_state=FIX_RAND_STATE))\n",
    "          #, ('knn',  KNeighborsRegressor())                                     \n",
    "          #,('tree', DecisionTreeRegressor( random_state=FIX_RAND_STATE))\n",
    "          # ,('rf', RandomForestRegressor( random_state=FIX_RAND_STATE )) #random_state=FIX_RAND_STATE\n",
    "          #, ('sk_xgb', ensemble.GradientBoostingClassifier(random_state=FIX_RAND_STATE))\n",
    "          #, ('xgb', xgboost.XGBClassifier(random_state=FIX_RAND_STATE))\n",
    "           #('catgb'. CatBoostRegressor())\n",
    "          , ('lgbmr', LGBMRegressor())\n",
    "          ]\n",
    "\n",
    "modelsDic = dict(models)\n",
    "\n",
    "\n",
    "model_params = {\n",
    "              #   'knn__n_neighbors': [5]\n",
    "               'lasso__alpha': [1] #.001,.01, .1, 1, 10, 100, 1000, 10000, 100000\n",
    "              #, 'tree__max_features':['sqrt']\n",
    "              #,  'lasso__penalty':['l2'] #'l1',\n",
    "              #, 'svm__C': [1] #.001,.01, .1, 1, 10, 100, 1000, 10000, 100000\n",
    "              #, 'svm__kernel':  ['linear', 'rbf']\n",
    "              # ,'rf__max_features':['sqrt'] #, 'log2', 'auto'\n",
    "              # , 'catgb__n?estimators' : [100]\n",
    "              #, 'rf__n_estimators': [1000]\n",
    "              #, 'sk_xgb__max_depth':[2,3]\n",
    "              #, 'sk_xgb__subsample': [1.0]\n",
    "              #, 'sk_xgb__max_features':['auto', 'sqrt', 'log2']\n",
    "              #, 'sk_xgb__n_estimators':[500]\n",
    "              #, 'xgb__learning_rate':[0.01]\n",
    "              #, 'xgb__max_depth':[3] #2,3,4\n",
    "              #, 'xgb__colsample_bytree':[.7] #\n",
    "              #, 'xgb__subsample': [.8]\n",
    "              #, 'xgb__objective': ['binary:logistic']\n",
    "              #, 'xgb__gamma':[1]\n",
    "              #, 'xgb__n_estimators': [1000]\n",
    "               ,'lgbmr__n_estimators':[100] #, 'log2', 'auto'    \n",
    "        }\n",
    "\n",
    "\n",
    "preproc_hparams_count = np.prod([len(params_grid[k]) for k in params_grid.keys()])\n",
    "model_params_count = np.prod([len(model_params[k]) for k in model_params.keys()])\n",
    "combinations = preproc_hparams_count * model_params_count\n",
    "print('Total grid search space size: %.d combinations to test'% ( combinations) )\n",
    "\n",
    "scores = {}\n",
    "ftr_compress = False\n",
    "folds = 3\n",
    "\n",
    "\n",
    " \n",
    "import time #Measure gridSearchCV execution time\n",
    "start = time.time()\n",
    "print(modelsDic.keys())\n",
    "for model_name in list(modelsDic.keys()):\n",
    "    print('Training model %s ...' % model_name)\n",
    "    pipe = cached_pipe\n",
    "    pipe.steps.append((model_name, modelsDic[model_name]))\n",
    "    \n",
    "    #Add only model_name parameters to the grid dict\n",
    "    filtered_params = params_grid.copy() #Initialize with preprocess variations to test\n",
    "    for key in model_params.keys():\n",
    "        if model_name in key:\n",
    "            filtered_params[key]=model_params[key]\n",
    "            \n",
    "    cv_splitter = model_selection.KFold(n_splits=folds\n",
    "                                  , random_state=FIX_RAND_STATE)\n",
    "    \n",
    "    scorer = metrics.make_scorer(metrics.mean_squared_error)#, average = score_avg\n",
    "    performance_metric_name = scorer.__str__().rstrip(')').split('(')[1] # Extract scorer metric name\n",
    "\n",
    "    \n",
    "    gs = model_selection.GridSearchCV(estimator=pipe, param_grid = filtered_params\n",
    "                                  , cv = cv_splitter, n_jobs=-1,  scoring = scorer )\n",
    "    print(filtered_params)\n",
    "    \n",
    "    gs.fit(X_train, np.log1p(y_train))\n",
    "    scores[model_name] = None\n",
    "    scores[model_name]={'best_score':  gs.best_score_}\n",
    "    print(\"Best {}: {:.4f} with params: {}: \".format( performance_metric_name\n",
    "                                          , gs.best_score_, gs.best_params_))\n",
    "    \n",
    "    pipe.steps.pop()   #Pop model in turn from pipe\n",
    "\n",
    "    # Store best model results to plot i.e  those corresponding to best model params\n",
    "    cv_results_df = pd.DataFrame(gs.cv_results_)\n",
    "    # Get the best candidate parameter setting.\n",
    "    scores[model_name]['cv_optim_result'] = cv_results_df.loc[gs.best_index_,:]\n",
    "    scores[model_name]['best_estimator'] = gs.best_estimator_\n",
    "        \n",
    "end = time.time()\n",
    "total_elapsed_seconds = end - start\n",
    "print('Grid search elapsed time: %.2f minutes'% (total_elapsed_seconds/60))\n",
    "\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 175,
=======
   "execution_count": 70,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": [
       "['code_postal',\n",
       " 'date_mutation',\n",
       " 'id_parcelle',\n",
       " 'nature_culture',\n",
       " 'nom_commune',\n",
       " 'type_local']"
      ]
     },
     "execution_count": 175,
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lasso__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, mean_fit_time, std_fit_time, mean_score_time, std_score_time, param_lasso__alpha, params, split0_test_score, split1_test_score, split2_test_score, mean_test_score, std_test_score, rank_test_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# let's capture the categorical variables first\n",
    "cat_vars = [var for var in features if X_train[var].dtype == 'O']\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: persisting the frequent labels\n",
    "\n",
    "As you will see in future sections, one of the key pieces of deploying the model is \"Model Validation\". Model validation refers to corroborating that the deployed model and the model built during research, are identical. The entire pipeline needs to produce identical results.\n",
    "\n",
    "Therefore, in order to check at the end of the process, that the feature engineering pipelines are identical, we will save -we will persist-, the list of frequent labels per variable, so that we can use it at the end, to corroborate our models."
=======
    "first_model = list(scores.keys())[0] # Just to get columns of results summary\n",
    "\n",
    "results_pd = pd.DataFrame(None, columns = ['model'] + list(scores[first_model]['cv_optim_result'].index))\n",
    "results_pd"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_labels(df, var, rare_perc):\n",
    "    # finds the labels that are shared by more than a certain % of the houses in the dataset\n",
    "    df = df.copy()\n",
    "    tmp = df.groupby(var)['valeur_fonciere'].count() / len(df)\n",
    "    return tmp[tmp>rare_perc].index\n",
    "\n",
    "frequent_labels_dict = {}\n",
    "\n",
    "for var in cat_vars:\n",
    "    frequent_ls = find_frequent_labels(X_train, var, 0.01)\n",
    "    \n",
    "    # we save the list in a dictionary\n",
    "    frequent_labels_dict[var] = frequent_ls\n",
    "    \n",
    "    X_train[var] = np.where(X_train[var].isin(frequent_ls), X_train[var], 'Rare')\n",
    "    X_test[var] = np.where(X_test[var].isin(frequent_ls), X_test[var], 'Rare')\n",
    "    \n",
    "# now we save the dictionary\n",
    "np.save('../../models/FrequentLabels.npy', frequent_labels_dict)"
=======
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbmr'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performance = [(k,scores[k]['best_score']) for k in scores.keys()]\n",
    "best_model = sorted(models_performance, key=lambda x: x[1], reverse=False)[0][0]\n",
    "best_model"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 177,
=======
   "execution_count": 102,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'code_postal': Index([], dtype='object', name='code_postal'),\n",
       " 'date_mutation': Index([], dtype='object', name='date_mutation'),\n",
       " 'id_parcelle': Index([], dtype='object', name='id_parcelle'),\n",
       " 'nature_culture': Index(['Missing', 'futaies résineuses', 'jardins', 'landes', 'prés', 'sols',\n",
       "        'taillis simples', 'terrains a bâtir', 'terrains d'agrément', 'terres',\n",
       "        'vignes'],\n",
       "       dtype='object', name='nature_culture'),\n",
       " 'nom_commune': Index([], dtype='object', name='nom_commune'),\n",
       " 'type_local': Index(['Appartement', 'Dépendance', 'Local industriel. commercial ou assimilé',\n",
       "        'Maison', 'Missing'],\n",
       "       dtype='object', name='type_local')}"
      ]
     },
     "execution_count": 177,
=======
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 102,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "frequent_labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to transform the strings of these variables into numbers. We will do it so that we capture the monotonic relationship between the label and the target:"
=======
    "scores[best_model]['best_estimator'][-1]"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will assign discrete values to the strings of the variables, \n",
    "# so that the smaller value corresponds to the smaller mean of target\n",
    "\n",
    "def replace_categories(train, test, var, target):\n",
    "    ordered_labels = train.groupby([var])[target].mean().sort_values().index\n",
    "    ordinal_label = {k:i for i, k in enumerate(ordered_labels, 0)} \n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores."
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    replace_categories(X_train, X_test, var, 'valeur_fonciere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_train[var].isnull().sum()>0]"
=======
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(235000.0, 191964.15914295975), (105400.0, 116464.63700847368), (86000.0, 170568.6660852802), (35000.0, 56446.99604979182), (181000.0, 197161.3138493486), (61000.0, 59503.20563856964), (57300.0, 83417.26473333043), (91000.0, 83728.69597149626), (71500.0, 72548.45868753687), (25000.0, 70899.02731746994)]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.expm1(scores[best_model]['best_estimator'].predict(X_test))\n",
    "print(list(zip(y_test,y_pred))[0:10])\n",
    "\n"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_test[var].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "For use in linear models, features need to be either scaled or normalised. In the next section, I will scale features between the min and max values:"
=======
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model performance: 1953984.75 \n"
     ]
    }
   ],
   "source": [
    "# Base estimator is the overall mean\n",
    "m = y_test.median()\n",
    "y_pred =[m for m in range(len(y_test))]\n",
    "\n",
    "performance = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Base model performance: {:.2f} '.format(performance))"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the target\n",
    "y_train = X_train['valeur_fonciere']\n",
    "y_test = X_test['valeur_fonciere']"
=======
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model performance: 1767979.84\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.expm1(scores[best_model]['best_estimator'].predict(X_test))\n",
    "\n",
    "performance = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Base model performance: {:.2f}'.format(performance))"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/scaler.pkl']"
      ]
     },
     "execution_count": 183,
=======
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191964.15914296 116464.63700847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93330    235000.0\n",
       "29290    105400.0\n",
       "Name: valeur_fonciere, dtype: float64"
      ]
     },
     "execution_count": 138,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# fit scaler\n",
    "scaler = MinMaxScaler() # create an instance\n",
    "scaler.fit(X_train[features]) #  fit  the scaler to the train set for later use\n",
    "\n",
    "# we persist the model for future use\n",
    "joblib.dump(scaler, '../../models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "X_train = pd.DataFrame(scaler.transform(X_train[features]), columns=features)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test[features]), columns=features)"
=======
    "from joblib import dump, load\n",
    "\n",
    "dump(scores[best_model][ 'best_estimator'], '../../models/model.joblib') \n",
    "clf3 = load('../../models/model.joblib') \n",
    "new_vals = X_test[0:2]\n",
    "new_preds = np.expm1(clf3.predict(new_val))\n",
    "print(new_preds)\n",
    "y_test[0:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export first test data as example for frontend app"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 185,
=======
   "execution_count": 143,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>code_postal</th>\n",
       "      <th>date_mutation</th>\n",
       "      <th>id_parcelle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nature_culture</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>nombre_lots</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
       "      <th>numero_disposition</th>\n",
=======
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>type_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970994</td>\n",
       "      <td>0.550094</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896280</td>\n",
       "      <td>0.591264</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941102</td>\n",
       "      <td>0.552015</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.517275</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914319</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.50</td>\n",
=======
       "      <td>134133</td>\n",
       "      <td>43.822579</td>\n",
       "      <td>4.362797</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Appartement</td>\n",
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   code_postal  date_mutation  id_parcelle  latitude  longitude  \\\n",
       "0          0.0            0.0          0.0  0.970994   0.550094   \n",
       "1          0.0            0.0          0.0  0.896280   0.591264   \n",
       "2          0.0            0.0          0.0  0.941102   0.552015   \n",
       "3          0.0            0.0          0.0  0.947205   0.517275   \n",
       "4          0.0            0.0          0.0  0.914319   0.526196   \n",
       "\n",
       "   nature_culture  nom_commune  nombre_lots  nombre_pieces_principales  \\\n",
       "0        0.909091          0.0     0.005714                   0.000000   \n",
       "1        0.909091          0.0     0.005714                   0.000000   \n",
       "2        0.272727          0.0     0.000000                   0.000000   \n",
       "3        0.636364          0.0     0.000000                   0.000000   \n",
       "4        0.818182          0.0     0.000000                   0.121212   \n",
       "\n",
       "   numero_disposition  surface_reelle_bati  surface_terrain  type_local  \n",
       "0                 0.0             0.000367         0.000726        0.25  \n",
       "1                 0.0             0.000367         0.000726        0.25  \n",
       "2                 0.0             0.000367         0.012155        0.00  \n",
       "3                 0.0             0.000367         0.002244        0.00  \n",
       "4                 0.0             0.000423         0.000842        0.50  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296347"
      ]
     },
     "execution_count": 186,
=======
       "         latitude  longitude  nombre_pieces_principales  surface_reelle_bati  \\\n",
       "134133  43.822579   4.362797                        2.0                 50.0   \n",
       "\n",
       "        surface_terrain   type_local  \n",
       "134133              0.0  Appartement  "
      ]
     },
     "execution_count": 143,
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "y_train.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/model.pkl']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "models = { 'lasso': Lasso(alpha=0.005, random_state=SEED)           # REMEMBER to set the random_state / seed\n",
    "          ,'treeReg': DecisionTreeRegressor(random_state=SEED)\n",
    "         }\n",
    "\n",
    "\n",
    "model = models['treeReg']\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# we persist the model for future use\n",
    "joblib.dump(model, '../../models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mse: 62821172688.4176\n",
      "Train rmse: 250641.5222751761\n",
      "\n",
      "Test mse: 14871396475009.244\n",
      "Test rmse: 3856344.9631755254\n",
      "\n",
      "Average property price:  132000.9999999999\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model:\n",
    "# remember that we log transformed the output (SalePrice) in our feature engineering notebook / lecture.\n",
    "\n",
    "# In order to get the true performance of the Lasso\n",
    "# we need to transform both the target and the predictions\n",
    "# back to the original house prices values.\n",
    "# \n",
    "# We will evaluate performance using the mean squared error and the\n",
    "# root of the mean squared error\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print('Train mse: {}'.format(mean_squared_error(np.exp(y_train), np.exp(pred))))\n",
    "print('Train rmse: {}'.format(sqrt(mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print()\n",
    "pred = model.predict(X_test)\n",
    "print('Test mse: {}'.format(mean_squared_error(np.exp(y_test), np.exp(pred))))\n",
    "print('Test rmse: {}'.format(sqrt(mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print()\n",
    "print('Average property price: ', np.exp(y_train).median())"
=======
    "\n",
    "X_test.tail(1).to_csv('../../data/ui/input_data_sample.csv', index=False)\n",
    "\n",
    "X_test.tail(1)"
>>>>>>> 1bab5b01c9c25c94b3f61cd1d3d396747c59d734
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
